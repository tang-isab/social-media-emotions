{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a33202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bumblebealu/.conda/envs/cse/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bumblebealu/.conda/envs/cse/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/bumblebealu/.conda/envs/cse/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-03-06 16:16:20.961893: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, Trainer, TrainingArguments, DistilBertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea870b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b50cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(X, y, max_length=128): \n",
    "    encodings = tokenizer(X, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(y, dtype=torch.float)\n",
    "    return EmotionDataset(encodings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f94d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326cfc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df.iloc[:, 1:], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5a2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b47e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05677ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(train_encodings, y_train.values)\n",
    "test_dataset = EmotionDataset(test_encodings, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a9b8820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1, \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8, \n",
    "    warmup_steps=0,\n",
    "    weight_decay=0,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c48438",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af230c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21721' max='40808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21721/40808 3:31:19 < 3:05:42, 1.71 it/s, Epoch 0.53/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3850' max='17489' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3850/17489 04:50 < 17:09, 13.25 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bab22c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
    "\n",
    "threshold = 0.5\n",
    "pred_labels = (probabilities > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1585eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_flat = y_test.values.flatten()\n",
    "pred_labels_flat = pred_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d4df411",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true_flat, pred_labels_flat, average='binary')\n",
    "recall = recall_score(y_true_flat, pred_labels_flat, average='binary')\n",
    "f1 = f1_score(y_true_flat, pred_labels_flat, average='binary')\n",
    "accuracy = accuracy_score(y_true_flat, pred_labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071d3a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9251517049258211\n",
      "Recall: 0.9157125248480616\n",
      "F1 Score: 0.9204079148076799\n",
      "Accuracy: 0.9735214515790878\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cse]",
   "language": "python",
   "name": "conda-env-.conda-cse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
